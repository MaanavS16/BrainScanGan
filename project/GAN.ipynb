{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create noise vector -- drawn from normal dist\n",
    "def get_noise(n_samples, z_dim, device, im_chan=1):\n",
    "    return torch.randn(n_samples, z_dim*im_chan, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator steps:\n",
    "- Create noise vector of shape: (# samples, # elements)\n",
    "- Reshape to (# samples, # elements, 1, 1); i.e. each element in the noise vector is converted into a 1x1 matrix\n",
    "- Transpose convolve the 1x1 matrix to desired shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scan_slices(sample_element, scan_type='', x=100, cmap='gray'):\n",
    "    print(\"{} Scan\".format(scan_type))\n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(1,3) \n",
    "    plt.title(\"Brain Scan Slices\")\n",
    "\n",
    "    axarr[0].imshow(sample_element[x], cmap=cmap)\n",
    "    axarr[0].title.set_text(\"Slice with fixed X\")\n",
    "    axarr[1].imshow(sample_element[:,x], cmap=cmap)\n",
    "    axarr[1].title.set_text(\"Slice with fixed Y\")\n",
    "    axarr[2].imshow(sample_element[:,:,x], cmap=cmap)\n",
    "    axarr[2].title.set_text(\"Slice with fixed Z\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimmension of a transpose convolution along any axis can be found with the formula:\n",
    "\n",
    "$X_{out}[i] = X_{in}[i]*S[i]-2*P[i]+D[i]*(K[i]-1)+1$\n",
    "\n",
    "where S, P, D, K are the vectors representing the Stride, Padding, Dilation, and Kernel along all axis respectively\n",
    "For simplicity in our 3D tranpose convolution, let S=(2,2,2) P=(0,0,0) D=(1,1,1) in all layers and adjust the Kernel to reach the desired output shape.\n",
    "\n",
    "With this simplifcation the output shape over n composed transpose convolutions is greatly reduced in complexity to :\n",
    "\n",
    "$Gf(X_{in}[i]) = X_{out}[i]$\n",
    "\n",
    "$f^n(X_{in}[i]) = \\sum_{j=0}^{n} 2^{n-j}(K_j[i]-1)$\n",
    "\n",
    "With this one of the possible arrangements of the kernels $K_j$ to reach the target shape is found in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n",
      "Output dim: (290,290,203)\n"
     ]
    }
   ],
   "source": [
    "def compute_new_size(input_size, kernel, stride=2, padding=0, dilation=1):\n",
    "    return (input_size-1)*stride - 2*padding + dilation*(kernel-1) + 1\n",
    "\n",
    "\n",
    "\n",
    "def get_dim_s2(k):\n",
    "    sum = 0\n",
    "    n = len(k)-1\n",
    "    for i, x in enumerate(k[:-1]):\n",
    "        sum += 2**(n-i)*(x-1)\n",
    "    return sum + k[-1]\n",
    "\n",
    "print(get_dim_s2([6,5,5,7,5,2]))\n",
    "\n",
    "\n",
    "\n",
    "# verify solution\n",
    "x0, y0 = 1, 1\n",
    "x1, y1 = compute_new_size(x0, 6), compute_new_size(y0, 5)\n",
    "x2, y2 = compute_new_size(x1, 5), compute_new_size(y1, 3)\n",
    "x3, y3 = compute_new_size(x2, 5), compute_new_size(y2, 3)\n",
    "x4, y4 = compute_new_size(x3, 7), compute_new_size(y3, 5)\n",
    "x5, y5 = compute_new_size(x4, 5), compute_new_size(y4, 5)\n",
    "x6, y6 = compute_new_size(x5, 2), compute_new_size(y5, 3)\n",
    "print(\"Output dim: ({},{},{})\".format(x6,x6,y6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 2, kernel_size=(6,6,5)),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim * 2, kernel_size=(5,5,3)),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim*4, kernel_size=(5,5,3)),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim*2, kernel_size=(7,7,5)),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim, kernel_size=5),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=(2,2,3), final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "\n",
    "        # Build the neural block\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose3d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm3d(output_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose3d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "    def unsqueeze_noise(self, noise):\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test generator\n",
    "if test:\n",
    "    with torch.no_grad():\n",
    "        gen = Generator(z_dim=100, im_chan=1).cuda()\n",
    "        z = gen.unsqueeze_noise(get_noise(2, 100, device))\n",
    "        print(z.shape)\n",
    "        y = gen(z)\n",
    "        print(y.shape)\n",
    "        show_scan_slices(y[0][0].cpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrimator Steps:\n",
    "* Input batch of images Shape: (# samples, 1, 290, 290, 203) -- output from generator and real image batches\n",
    "* 3D convolve samples\n",
    "* targert size for convolutions: (# Samples, 1)\n",
    "\n",
    "This process can be done with the sequence of Kernel vectors from the generator in reverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define discriminator\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, im_chan=1, hidden_dim=8):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim, kernel_size=(2,2,3)),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2, kernel_size=5),\n",
    "            self.make_disc_block(hidden_dim*2, hidden_dim * 4, kernel_size=(7,7,5)),\n",
    "            self.make_disc_block(hidden_dim*4, hidden_dim * 2, kernel_size=(5,5,3)),\n",
    "            self.make_disc_block(hidden_dim*2, hidden_dim * 2, kernel_size=(5,5,3)),\n",
    "            self.make_disc_block(hidden_dim * 2, 1, kernel_size=(6,6,5), final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv3d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm3d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                nn.Conv3d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    disc = Discriminator(im_chan=1).cuda()\n",
    "    pred = disc(y)\n",
    "    print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "z_dim = 256\n",
    "display_step = 5\n",
    "batch_size = 2\n",
    "lr = 0.002\n",
    "epochs = 10\n",
    "c_lambda = 10 #coefficient of gradient penalty\n",
    "disc_repeats = 5\n",
    "gen_repeats = 5\n",
    "\n",
    "# optimizer momentum parameters\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "\n",
    "\n",
    "# initialize gen, disc, and optimizer \n",
    "gen = Generator(z_dim, im_chan=1, hidden_dim=16).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "disc = Discriminator(im_chan=1, hidden_dim=8).to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "# initialize network weights -- W ~ N(0,.02^2)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm3d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss of this model will be defined as:\n",
    "\n",
    "$\\underset{g}{min}$ $\\underset{d}{max}$ $E[d(x)]-E[d(g(z))]+\\lambda(||\\nabla d(\\hat{x})||_2 -1)^2$\n",
    "\n",
    "$\\text{where g is the generator and d is the discriminator}$\n",
    "\n",
    "This loss is known as wasserstein loss:\n",
    "* The generator is motivated to maximize the degree to which the disciminator believes generated samples are real\n",
    "    * $\\underset{g}{min}$ $-E[d(g(z))]$\n",
    "* The disciminator is motivated to maximize the degree to which real images are believed to be real and is punished for beliving generated images to be real\n",
    "    * $\\underset{d}{max}$ $E[d(x)]-E[d(g(z))]$\n",
    "* The disciminator is also punished for having an L1-Gradient Norm greater than 1 (Causes issues with W-Loss)\n",
    "    * Gradient is computed at intermediate point between real $x$ and fake $g(z)$ known as $\\hat{x}$ (approxinated by tensor interpolation)\n",
    "    * $\\underset{d}{max}$ $\\lambda(||\\nabla d(\\hat{x})||_2 -1)^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# poll gradient with interpolated sample\n",
    "def get_gradient(disc, real, fake, epsilon):\n",
    "\n",
    "    # interpolate real and fake samples\n",
    "    mixed_images = torch.add(real * epsilon, fake * (1 - epsilon))\n",
    "    #print(mixed_images.shape)\n",
    "    mixed_scores = disc(mixed_images)\n",
    "    \n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores), \n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return gradient\n",
    "\n",
    "# compute l1 gradient penalty\n",
    "def gradient_penalty(gradient):\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "    # Calculate the magnitude of every row\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    penalty = torch.mean((gradient_norm - torch.ones_like(gradient_norm))**2)\n",
    "    return penalty\n",
    "\n",
    "# define gen w-loss\n",
    "def get_gen_loss(disc_fake_pred):\n",
    "    gen_loss = -torch.mean(disc_fake_pred)\n",
    "    return gen_loss\n",
    "\n",
    "# define disc w-loss (with l1 norm)\n",
    "def get_disc_loss(disc_fake_pred, disc_real_pred, gp, c_lambda):\n",
    "    disc_loss = torch.mean(disc_fake_pred) + torch.mean(gp)*c_lambda - torch.mean(disc_real_pred)\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os    \n",
    "\n",
    "# define brain dataset\n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, scan_type=\"T2w\"):\n",
    "        self.scan_type=scan_type\n",
    "        self.path = os.path.join(os.path.dirname(os.getcwd()), \"research_dataset\", \"ds\", self.scan_type)\n",
    "        self.file_names = os.listdir(self.path)\n",
    "        self.length = len(self.file_names)\n",
    "\n",
    "    def reshape_samples(self, x):\n",
    "        x = x[:,:,67:-20] # slice z down to 203\n",
    "        p1, p2 = np.zeros((36, 290, 203)), np.zeros((37, 290, 203))\n",
    "        x = np.concatenate((p1, x, p2), axis=0) # pad x up to 290 by evenly concatinating zero 290*203 tensors\n",
    "        return x\n",
    "\n",
    "    def path_to_array(self, path):\n",
    "        image_array = nib.load(path)\n",
    "        image_array = image_array.get_fdata()\n",
    "        return np.array(image_array)\n",
    "\n",
    "    # get scan as numpy array -- reshape irregular images according to preprocess.ipynb\n",
    "    def __getitem__(self, index):\n",
    "        item_path = os.path.join(self.path, self.file_names[index])\n",
    "        item = self.path_to_array(item_path)\n",
    "        if item.shape != (290, 290, 203):\n",
    "            item = self.reshape_samples(item)\n",
    "        if self.scan_type==\"T2w\":\n",
    "            item = item/88\n",
    "        else:\n",
    "            item = item/3    \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(BrainDataset(), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(dataloader):\n",
    "        cur_batch_size = len(batch)\n",
    "        real = batch.view((cur_batch_size, 1, 290, 290, 203)).to(device, dtype=torch.float)\n",
    "        #print(real.shape)\n",
    "\n",
    "\n",
    "        for _ in range(disc_repeats):\n",
    "            ## Update discriminator\n",
    "            disc_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            disc_fake_pred = disc(fake.detach())\n",
    "            disc_real_pred = disc(real)\n",
    "\n",
    "            # interpolate real and fake with random factor for GP\n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, 1, device=device, requires_grad=True)\n",
    "            grad = get_gradient(disc, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(grad)\n",
    "            disc_loss = get_disc_loss(disc_fake_pred, disc_real_pred, gp, c_lambda)\n",
    "\n",
    "            disc_loss.backward(retain_graph=True)\n",
    "            disc_opt.step()\n",
    "\n",
    "        ## Update generator\n",
    "        for _ in range(gen_repeats):\n",
    "            gen_opt.zero_grad()\n",
    "            fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake_2 = gen(fake_noise_2)\n",
    "            disc_fake_pred = disc(fake_2)\n",
    "\n",
    "            gen_loss =get_gen_loss(disc_fake_pred)\n",
    "\n",
    "            gen_loss.backward()\n",
    "            gen_opt.step()\n",
    "        \n",
    "\n",
    "        # Keep track of the average disc and gen loss\n",
    "        disc_loss_v, gen_loss_v = disc_loss.item(), gen_loss.item()\n",
    "        mean_discriminator_loss += disc_loss_v / display_step\n",
    "        mean_generator_loss += gen_loss_v / display_step\n",
    "\n",
    "        # dynamically adjust train cycles to gen or disc domination\n",
    "        if mean_discriminator_loss > mean_generator_loss:\n",
    "            disc_repeats = 5\n",
    "            gen_repeats = 1\n",
    "        else:\n",
    "            disc_repeats = 1\n",
    "            gen_repeats = 5\n",
    "\n",
    "        if cur_step % display_step == 0:\n",
    "            with torch.no_grad():\n",
    "                print(f\"Step {cur_step}: Generator loss: {disc_loss_v}, discriminator loss: {gen_loss_v}\")\n",
    "                fake_noise = get_noise(1, z_dim, device=device)\n",
    "                fake = gen(fake_noise)[0][0].cpu()\n",
    "                show_scan_slices(fake, scan_type=\"T2w\")\n",
    "                show_scan_slices(real[0][0].cpu(), scan_type=\"T2w\")\n",
    "        cur_step += 1\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
